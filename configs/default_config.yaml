
   
# Training configuration  
training:  
  max_epochs: 200
  learning_rate: 0.001
  weight_decay: 0.0001
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  seed : 42
  img_size: [448, 448]
  batch_size: 16
  num_workers: 4
  augmentation: true  
  
# Optimizer configuration
optimizer:
  type: AdamW
  betas: [0.9, 0.999]
  eps: 1e-08

# Scheduler configuration
scheduler:
  type: CosineAnnealingLR
  T_max: 100
  eta_min: 1e-06
  
# Loss configuration
# loss:
  
  
# Callbacks configuration
callbacks:
  checkpoint:
    experiment_name: "face_depth"
    checkpoint_dir: './experiments/checkpoints'
    monitor: val/loss
    mode: min
    save_top_k: 3
    every_n_epochs: 1
    save_last: true
  early_stopping:
    monitor: val/loss
    patience: 15
    mode: min
    
# Hardware configuration
hardware:
  gpus: [0, 1, 2, 3] # [0, 1, 2, 3,]
  accelerator: gpu
  precision: 32  # Use mixed precision if available
  
# Logging configuration
logging:
  log_dir: ./experiments/logs  
  log_every_n_steps: 10
  val_check_interval: 1.0
  check_val_every_n_epoch : 2
  

datasets:
  - type: synthhuman
    data_dir: /media/idc-r2w2/data_sdc/jseob/data/synthhuman
    bg_dir : None    
    weight: 0.35  # Optional: sampling weight

  - type: merged
    data_dir: /media/idc-r2w2/data_sdc/jseob/data/head_uvd
    bg_dir: /media/idc-r2w2/data_sdc/jseob/data/no_humans
    weight: 0.65    

